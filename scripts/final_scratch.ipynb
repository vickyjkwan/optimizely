{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import popelines\n",
    "import os\n",
    "from main import fix_values, populating_vals, flatten, flatten_dupe_vals\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_values(value, key, reset_key):\n",
    "    if key == reset_key:\n",
    "        new_list = []\n",
    "        for x in value:\n",
    "            value[x][f'{reset_key}_id'] = x\n",
    "            new_list.append(value[x])\n",
    "        return new_list\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read endpoint, returns a json file of the HTTP request\n",
    "def read_endpoint(endpoint, headers_set, params_set=None):\n",
    "    try:\n",
    "        response = requests.get(endpoint, headers=headers_set, params=params_set)\n",
    "        response_text = json.loads(response.text)\n",
    "        response.raise_for_status()\n",
    "\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate all experiments given a project id\n",
    "# def generate_experiments(project_id, experiment_endpoint, experiment_headers, experiment_params):\n",
    "#     # get all experiments from one project\n",
    "#     j_exp = read_endpoint(endpoint=experiment_endpoint, headers_set=experiment_headers, params_set=experiment_params)\n",
    "\n",
    "#     # loop for all experiments in this project\n",
    "# #     experiment_id_list = []\n",
    "# #     upload_exp_list = []\n",
    "# #     for exp in j_exp:\n",
    "# #         exp['project_id'] = project_id\n",
    "# #         upload_exp_list.append(flatten(exp, {}, ''))\n",
    "# #         experiment_id_list.append(exp['id'])\n",
    "        \n",
    "#     return upload_exp_list, experiment_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all projects within account\n",
    "def generate_projects(project_endpoint, project_headers):\n",
    "    # get all projects\n",
    "    j_proj = read_endpoint(endpoint=project_endpoint, headers_set=project_headers)\n",
    "\n",
    "    # store a list of project metadata\n",
    "    return j_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all projects, get project_id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbq_key = os.environ.get('GOOGLE_ACCOUNT_CREDENTIALS')\n",
    "pope = popelines.popeline(dataset_id='optimizely', service_key_file_loc=gbq_key, directory='.', verbose=False)\n",
    "\n",
    "# Optimizely parameters\n",
    "headers = {\n",
    "    'Authorization': 'Bearer 2:EWAWmaXb4TgtYVU2VvwoEF-9UbJxBahkiFh1633_Oc9nmju7iJis',\n",
    "    'Content-Type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_endpoint = 'https://api.optimizely.com/v2/projects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects = generate_projects(project_endpoint, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pope.write_to_json(file_name='../uploads/projects.json', jayson=all_projects, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pope.write_to_bq(table_name='projects', file_name='../uploads/projects.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "# print(\"Successfully uploaded all projects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_list = []\n",
    "for project in all_projects:\n",
    "    project_id_list.append((project['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_id_name = []\n",
    "# for project in all_projects:\n",
    "#     project_id_name.append((project['id'], project['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_id_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_endpoint = 'https://api.optimizely.com/v2/experiments'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_id_list = []\n",
    "# all_exp_list = []\n",
    "\n",
    "# for project_id in project_id_list:\n",
    "    # params include project_id (required) and experiments pulling per each request (default only 25)\n",
    "params = (\n",
    "    ('project_id', 10427612860),\n",
    "    ('per_page', 100),\n",
    ") \n",
    "\n",
    "#     exp_list = read_endpoint(endpoint=experiment_endpoint, headers_set=headers, params_set=params)\n",
    "#     all_exp_list.extend(exp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_list = read_endpoint(endpoint=experiment_endpoint, headers_set=headers, params_set=params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_id_list = []\n",
    "for exp in exp_list:\n",
    "    exp_id_list.append(exp['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id_list.extend(exp_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in exp_list:\n",
    "    if e['id'] == 12746930280:\n",
    "        new = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allocation_policy': 'manual',\n",
       " 'audience_conditions': 'everyone',\n",
       " 'campaign_id': 12747070594,\n",
       " 'changes': [],\n",
       " 'created': '2019-01-04T00:26:41.931766Z',\n",
       " 'description': 'Text in the hero seems off. Title is not title-case. Copy is wordy and contains no CTA. Subtitle font is odd. Subtitle font size takes up significant space. Padding between logo and text pushes form down too far\\n\\nHypothesis:\\nDirect copy that includes a CTA will improve conversion rate.\\nReducing hero size will move form up above the fold and increase conversion rate.\\n',\n",
       " 'earliest': '2019-01-07T23:54:30.487191Z',\n",
       " 'holdback': 0,\n",
       " 'id': 12746930280,\n",
       " 'is_classic': False,\n",
       " 'last_modified': '2019-01-08T01:04:38.295113Z',\n",
       " 'metrics': [{'aggregator': 'unique',\n",
       "   'event_id': 12826470463,\n",
       "   'scope': 'visitor',\n",
       "   'winning_direction': 'increasing'},\n",
       "  {'aggregator': 'bounce',\n",
       "   'event_id': 12818980502,\n",
       "   'scope': 'event',\n",
       "   'winning_direction': 'decreasing'}],\n",
       " 'name': '2019-0107-Headline Test-25 Automations',\n",
       " 'project_id': 10427612860,\n",
       " 'status': 'running',\n",
       " 'type': 'a/b',\n",
       " 'url_targeting': {'activation_type': 'immediate',\n",
       "  'conditions': '[\"and\", [\"or\", {\"match_type\": \"substring\", \"type\": \"url\", \"value\": \"https://pages.infusionsoft.com/25_things_to_automate_gate\"}]]',\n",
       "  'edit_url': 'https://pages.infusionsoft.com/25_things_to_automate_gate',\n",
       "  'key': '10427612860_url_targeting_for_20190103headline_copy_test__25_thi',\n",
       "  'page_id': 12739870165},\n",
       " 'variations': [{'actions': [],\n",
       "   'archived': False,\n",
       "   'name': 'Original',\n",
       "   'status': 'active',\n",
       "   'variation_id': 12741310142,\n",
       "   'weight': 5000},\n",
       "  {'actions': [{'changes': [{'async': False,\n",
       "       'attributes': {'html': '25 Small Business Automations'},\n",
       "       'css': {},\n",
       "       'dependencies': [],\n",
       "       'id': '17A95734-F627-4D33-9E5A-2EF164FBB1B6',\n",
       "       'rearrange': {'insertSelector': '', 'operator': 'before'},\n",
       "       'selector': 'h1',\n",
       "       'type': 'attribute'},\n",
       "      {'async': False,\n",
       "       'attributes': {'html': 'Download the guide & eliminate repetitive tasks!',\n",
       "        'style': 'font-size: 20px;'},\n",
       "       'css': {},\n",
       "       'dependencies': [],\n",
       "       'id': 'AB803D26-CA3B-4470-B2D4-BC7EE0BC5AF8',\n",
       "       'rearrange': {'insertSelector': '', 'operator': 'before'},\n",
       "       'selector': '#exampleText',\n",
       "       'type': 'attribute'},\n",
       "      {'async': False,\n",
       "       'attributes': {'html': 'Enter your info to get started'},\n",
       "       'css': {},\n",
       "       'dependencies': [],\n",
       "       'id': 'B6BF4E68-0170-4B1A-8DE1-8C4FCB83C3F7',\n",
       "       'rearrange': {'insertSelector': '', 'operator': 'before'},\n",
       "       'selector': '.bolded-text',\n",
       "       'type': 'attribute'},\n",
       "      {'async': False,\n",
       "       'attributes': {'style': 'padding-top: 5px;'},\n",
       "       'css': {},\n",
       "       'dependencies': [],\n",
       "       'id': 'DFDC5B83-D5B3-47BD-A6CB-ED08233DD1CB',\n",
       "       'rearrange': {'insertSelector': '', 'operator': 'before'},\n",
       "       'selector': '#main_body',\n",
       "       'type': 'attribute'},\n",
       "      {'async': False,\n",
       "       'attributes': {'style': 'min-height: 450px; padding-top: 2px;'},\n",
       "       'css': {},\n",
       "       'dependencies': [],\n",
       "       'id': '882AF443-66B1-4C4E-A7D4-28B0261D8235',\n",
       "       'rearrange': {'insertSelector': '', 'operator': 'before'},\n",
       "       'selector': 'section:nth-of-type(2)',\n",
       "       'type': 'attribute'}],\n",
       "     'page_id': 12739870165,\n",
       "     'share_link': 'https://pages.infusionsoft.com/25_things_to_automate_gate?optimizely_token=811545cca72276fcca59490f31b030b3990957534e1d058bc6ff5643ffd0fa23&optimizely_x=12762280184&optimizely_x_audiences=&optimizely_preview_layer_ids=12747070594&optimizely_snippet=s3-10427612860'}],\n",
       "   'archived': False,\n",
       "   'name': 'Variation #1',\n",
       "   'status': 'active',\n",
       "   'variation_id': 12762280184,\n",
       "   'weight': 5000}]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single layer table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_singles = []\n",
    "nested_key_list = []\n",
    "for k,v in exp.items():\n",
    "    if isinstance(v, list):\n",
    "        nested_key_list.append(k)\n",
    "\n",
    "single_layer_experiment = {}    \n",
    "for k,v in exp.items():\n",
    "    if k not in nested_key_list:\n",
    "        k = k.replace('-', '_')\n",
    "        single_layer_experiment[k] = exp[k]\n",
    "single_layer_experiment['upload_ts'] = str(datetime.now())\n",
    "\n",
    "\n",
    "all_singles.append(flatten(single_layer_experiment, {}, ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'allocation_policy': 'manual',\n",
       "  'audience_conditions': 'everyone',\n",
       "  'campaign_id': 12747070594,\n",
       "  'created': '2019-01-04T00:26:41.931766Z',\n",
       "  'description': 'Text in the hero seems off. Title is not title-case. Copy is wordy and contains no CTA. Subtitle font is odd. Subtitle font size takes up significant space. Padding between logo and text pushes form down too far\\n\\nHypothesis:\\nDirect copy that includes a CTA will improve conversion rate.\\nReducing hero size will move form up above the fold and increase conversion rate.\\n',\n",
       "  'earliest': '2019-01-07T23:54:30.487191Z',\n",
       "  'holdback': 0,\n",
       "  'id': 12746930280,\n",
       "  'is_classic': False,\n",
       "  'last_modified': '2019-01-08T01:04:38.295113Z',\n",
       "  'name': '2019-0107-Headline Test-25 Automations',\n",
       "  'project_id': 10427612860,\n",
       "  'status': 'running',\n",
       "  'type': 'a/b',\n",
       "  'upload_ts': '2019-02-21 12:16:16.032962',\n",
       "  'url_targeting_activation_type': 'immediate',\n",
       "  'url_targeting_conditions': '[\"and\", [\"or\", {\"match_type\": \"substring\", \"type\": \"url\", \"value\": \"https://pages.infusionsoft.com/25_things_to_automate_gate\"}]]',\n",
       "  'url_targeting_edit_url': 'https://pages.infusionsoft.com/25_things_to_automate_gate',\n",
       "  'url_targeting_key': '10427612860_url_targeting_for_20190103headline_copy_test__25_thi',\n",
       "  'url_targeting_page_id': 12739870165}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_singles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unnested metrics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiment 11377370874\n",
      "Processing experiment 12107582952\n",
      "Processing experiment 12632940119\n",
      "Processing experiment 12722820205\n",
      "Processing experiment 12743540432\n",
      "Processing experiment 12746930280\n"
     ]
    }
   ],
   "source": [
    "metrics_table = []\n",
    "for exp in exp_list:\n",
    "    print(f\"Processing experiment {exp['id']}\")\n",
    "\n",
    "    # single layer fields:\n",
    "    nested_key_list = []\n",
    "    for k,v in exp.items():\n",
    "        if isinstance(v, list) or isinstance(v, dict):\n",
    "            nested_key_list.append(k)\n",
    "\n",
    "    single_layer_experiment = {}    \n",
    "    for k,v in exp.items():\n",
    "        if k not in nested_key_list:\n",
    "            k = k.replace('-', '_')\n",
    "            single_layer_experiment[k] = exp[k]\n",
    "    single_layer_experiment['upload_ts'] = str(datetime.now())\n",
    "\n",
    "    all_singles.append(flatten(single_layer_experiment, {}, ''))\n",
    "\n",
    "    # nested part into separate tables:\n",
    "    # metrics table:\n",
    "\n",
    "    flattened_metric = []\n",
    "    for element in exp['metrics']:\n",
    "        flattened_metric.append(element)\n",
    "\n",
    "    updated_metric = populating_vals(outer_dict=exp, inner_flattened_list=flattened_metric, destination_key='metrics')\n",
    "    new_flattened_metric = flatten_dupe_vals(vals=updated_metric, key='metrics')\n",
    "\n",
    "    metric_list = []\n",
    "    for metric in new_flattened_metric:\n",
    "        metric_dict = {}\n",
    "        metric_dict['metrics_aggregator'] = metric['metrics_aggregator']\n",
    "        if 'metrics_event_id' in metric.keys():\n",
    "            metric_dict['metrics_event_id'] = metric['metrics_event_id']\n",
    "        metric_dict['metrics_scope'] =  metric['metrics_scope']\n",
    "        metric_dict['metrics_winning_direction'] = metric['metrics_winning_direction']\n",
    "        metric_dict['experiment_id'] = exp['id']\n",
    "        metric_dict['upload_ts'] = str(datetime.now())\n",
    "        metric_list.append(metric_dict)\n",
    "        \n",
    "    metrics_table.extend(metric_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested part into separate tables:\n",
    "# metrics table:\n",
    "\n",
    "flattened_metric = []\n",
    "for element in exp['metrics']:\n",
    "    flattened_metric.append(element)\n",
    "\n",
    "updated_metric = populating_vals(outer_dict=exp, inner_flattened_list=flattened_metric, destination_key='metrics')\n",
    "new_flattened_metric = flatten_dupe_vals(vals=updated_metric, key='metrics')\n",
    "\n",
    "metric_list = []\n",
    "for metric in new_flattened_metric:\n",
    "    metric_dict = {}\n",
    "    metric_dict['metrics_aggregator'] = metric['metrics_aggregator']\n",
    "    if 'metrics_event_id' in metric.keys():\n",
    "        metric_dict['metrics_event_id'] = metric['metrics_event_id']\n",
    "    metric_dict['metrics_scope'] =  metric['metrics_scope']\n",
    "    metric_dict['metrics_winning_direction'] = metric['metrics_winning_direction']\n",
    "    metric_dict['experiment_id'] = exp['id']\n",
    "    metric_dict['upload_ts'] = str(datetime.now())\n",
    "    metric_list.append(metric_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'experiment_id': 12746930280,\n",
       "  'metrics_aggregator': 'unique',\n",
       "  'metrics_event_id': 12826470463,\n",
       "  'metrics_scope': 'visitor',\n",
       "  'metrics_winning_direction': 'increasing',\n",
       "  'upload_ts': '2019-02-21 12:16:20.793527'},\n",
       " {'experiment_id': 12746930280,\n",
       "  'metrics_aggregator': 'bounce',\n",
       "  'metrics_event_id': 12818980502,\n",
       "  'metrics_scope': 'event',\n",
       "  'metrics_winning_direction': 'decreasing',\n",
       "  'upload_ts': '2019-02-21 12:16:20.793543'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unnested variations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiment 11377370874\n",
      "Processing experiment 11377370874\n",
      "Processing experiment 12107582952\n",
      "Processing experiment 12107582952\n",
      "Processing experiment 12632940119\n",
      "Processing experiment 12632940119\n",
      "Processing experiment 12722820205\n",
      "Processing experiment 12722820205\n",
      "Processing experiment 12743540432\n",
      "Processing experiment 12743540432\n",
      "Processing experiment 12746930280\n",
      "Processing experiment 12746930280\n"
     ]
    }
   ],
   "source": [
    "variations_table = []\n",
    "for exp in exp_list:\n",
    "    print(f\"Processing experiment {exp['id']}\")\n",
    "\n",
    "    variations = {}\n",
    "    # for exp in exp_list:\n",
    "\n",
    "    print(f\"Processing experiment {exp['id']}\")\n",
    "\n",
    "    variations['experiment_id'] = exp['id']\n",
    "    variations['variations'] = exp['variations']\n",
    "\n",
    "    flattened_variations = []\n",
    "\n",
    "    for var in exp['variations']:\n",
    "        flattened_actions = []\n",
    "        if len(var['actions']) > 0:\n",
    "            for action in var['actions']:\n",
    "                flattened_changes = []\n",
    "                for element in action['changes']:\n",
    "                    flattened_changes.append(element)\n",
    "                # Replace old 'changes' with new 'flattened_changes'\n",
    "                updated_changes = populating_vals(outer_dict=action, inner_flattened_list=flattened_changes, destination_key='changes')\n",
    "                new_flattened_changes = flatten_dupe_vals(vals=updated_changes, key='changes')\n",
    "\n",
    "                update_actions = populating_vals(outer_dict=var, inner_flattened_list=new_flattened_changes, destination_key='actions')\n",
    "                flat = flatten_dupe_vals(vals=update_actions, key='actions')\n",
    "                flattened_actions.extend(flat)\n",
    "\n",
    "        else:\n",
    "            other_flat = {}\n",
    "            for k,v in var.items():\n",
    "                if k != 'actions':\n",
    "                    other_flat['actions'] = []\n",
    "                    other_flat[k] = v\n",
    "            flat = [other_flat]\n",
    "            flattened_actions.extend(flat)\n",
    "\n",
    "        update_variations = populating_vals(outer_dict=variations, inner_flattened_list=flattened_actions, destination_key='variations')\n",
    "        flattened_variations.extend(flatten_dupe_vals(vals=update_variations, key='variations'))\n",
    "\n",
    "    variations_table.extend(flattened_variations)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiment 12746930280\n"
     ]
    }
   ],
   "source": [
    "variations = {}\n",
    "# for exp in exp_list:\n",
    "\n",
    "print(f\"Processing experiment {exp['id']}\")\n",
    "\n",
    "variations['experiment_id'] = exp['id']\n",
    "variations['variations'] = exp['variations']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': [],\n",
       " 'archived': False,\n",
       " 'name': 'Original',\n",
       " 'status': 'active',\n",
       " 'variation_id': 12741310142,\n",
       " 'weight': 5000}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp['variations'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed round 2\n",
      "completed round 1\n"
     ]
    }
   ],
   "source": [
    "flattened_variations = []\n",
    "\n",
    "for var in exp['variations']:\n",
    "    flattened_actions = []  \n",
    "    \n",
    "    if len(var['actions']) > 0:\n",
    "        for action in var['actions']:\n",
    "\n",
    "            flattened_changes = []\n",
    "\n",
    "            if action['changes'] != []:\n",
    "                for element in action['changes']:\n",
    "                    flattened_changes.append(element)\n",
    "                # Replace old 'changes' with new 'flattened_changes'\n",
    "                updated_changes = populating_vals(outer_dict=action, inner_flattened_list=flattened_changes, destination_key='changes')\n",
    "                new_flattened_changes = flatten_dupe_vals(vals=updated_changes, key='changes')\n",
    "\n",
    "                update_actions = populating_vals(outer_dict=var, inner_flattened_list=new_flattened_changes, destination_key='actions')\n",
    "                flat = flatten_dupe_vals(vals=update_actions, key='actions')\n",
    "                flattened_actions.extend(flat)\n",
    "\n",
    "            else:\n",
    "                new_actions = flatten_dupe_vals(vals=var, key='actions')\n",
    "                flattened_actions.extend(new_actions)\n",
    "            \n",
    "            print('completed round 1')\n",
    "            \n",
    "    else:\n",
    "        other_flat = {}\n",
    "        for k,v in var.items():\n",
    "            if k != 'actions':\n",
    "                other_flat['actions'] = []\n",
    "                other_flat[k] = v\n",
    "        flat = [other_flat]\n",
    "        flattened_actions.extend(flat)\n",
    "\n",
    "        print('completed round 2')\n",
    "\n",
    "    update_variations = populating_vals(outer_dict=variations, inner_flattened_list=flattened_actions, destination_key='variations')\n",
    "    flattened_variations.extend(flatten_dupe_vals(vals=update_variations, key='variations'))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'experiment_id': 12746930280,\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Original',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 12741310142,\n",
       "  'variations_weight': 5000},\n",
       " {'experiment_id': 12746930280,\n",
       "  'variations_actions_changes_async': False,\n",
       "  'variations_actions_changes_attributes_html': '25 Small Business Automations',\n",
       "  'variations_actions_changes_id': '17A95734-F627-4D33-9E5A-2EF164FBB1B6',\n",
       "  'variations_actions_changes_rearrange_insertSelector': '',\n",
       "  'variations_actions_changes_rearrange_operator': 'before',\n",
       "  'variations_actions_changes_selector': 'h1',\n",
       "  'variations_actions_changes_type': 'attribute',\n",
       "  'variations_actions_page_id': 12739870165,\n",
       "  'variations_actions_share_link': 'https://pages.infusionsoft.com/25_things_to_automate_gate?optimizely_token=811545cca72276fcca59490f31b030b3990957534e1d058bc6ff5643ffd0fa23&optimizely_x=12762280184&optimizely_x_audiences=&optimizely_preview_layer_ids=12747070594&optimizely_snippet=s3-10427612860',\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Variation #1',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 12762280184,\n",
       "  'variations_weight': 5000},\n",
       " {'experiment_id': 12746930280,\n",
       "  'variations_actions_changes_async': False,\n",
       "  'variations_actions_changes_attributes_html': 'Download the guide & eliminate repetitive tasks!',\n",
       "  'variations_actions_changes_attributes_style': 'font-size: 20px;',\n",
       "  'variations_actions_changes_id': 'AB803D26-CA3B-4470-B2D4-BC7EE0BC5AF8',\n",
       "  'variations_actions_changes_rearrange_insertSelector': '',\n",
       "  'variations_actions_changes_rearrange_operator': 'before',\n",
       "  'variations_actions_changes_selector': '#exampleText',\n",
       "  'variations_actions_changes_type': 'attribute',\n",
       "  'variations_actions_page_id': 12739870165,\n",
       "  'variations_actions_share_link': 'https://pages.infusionsoft.com/25_things_to_automate_gate?optimizely_token=811545cca72276fcca59490f31b030b3990957534e1d058bc6ff5643ffd0fa23&optimizely_x=12762280184&optimizely_x_audiences=&optimizely_preview_layer_ids=12747070594&optimizely_snippet=s3-10427612860',\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Variation #1',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 12762280184,\n",
       "  'variations_weight': 5000},\n",
       " {'experiment_id': 12746930280,\n",
       "  'variations_actions_changes_async': False,\n",
       "  'variations_actions_changes_attributes_html': 'Enter your info to get started',\n",
       "  'variations_actions_changes_id': 'B6BF4E68-0170-4B1A-8DE1-8C4FCB83C3F7',\n",
       "  'variations_actions_changes_rearrange_insertSelector': '',\n",
       "  'variations_actions_changes_rearrange_operator': 'before',\n",
       "  'variations_actions_changes_selector': '.bolded-text',\n",
       "  'variations_actions_changes_type': 'attribute',\n",
       "  'variations_actions_page_id': 12739870165,\n",
       "  'variations_actions_share_link': 'https://pages.infusionsoft.com/25_things_to_automate_gate?optimizely_token=811545cca72276fcca59490f31b030b3990957534e1d058bc6ff5643ffd0fa23&optimizely_x=12762280184&optimizely_x_audiences=&optimizely_preview_layer_ids=12747070594&optimizely_snippet=s3-10427612860',\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Variation #1',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 12762280184,\n",
       "  'variations_weight': 5000},\n",
       " {'experiment_id': 12746930280,\n",
       "  'variations_actions_changes_async': False,\n",
       "  'variations_actions_changes_attributes_style': 'padding-top: 5px;',\n",
       "  'variations_actions_changes_id': 'DFDC5B83-D5B3-47BD-A6CB-ED08233DD1CB',\n",
       "  'variations_actions_changes_rearrange_insertSelector': '',\n",
       "  'variations_actions_changes_rearrange_operator': 'before',\n",
       "  'variations_actions_changes_selector': '#main_body',\n",
       "  'variations_actions_changes_type': 'attribute',\n",
       "  'variations_actions_page_id': 12739870165,\n",
       "  'variations_actions_share_link': 'https://pages.infusionsoft.com/25_things_to_automate_gate?optimizely_token=811545cca72276fcca59490f31b030b3990957534e1d058bc6ff5643ffd0fa23&optimizely_x=12762280184&optimizely_x_audiences=&optimizely_preview_layer_ids=12747070594&optimizely_snippet=s3-10427612860',\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Variation #1',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 12762280184,\n",
       "  'variations_weight': 5000},\n",
       " {'experiment_id': 12746930280,\n",
       "  'variations_actions_changes_async': False,\n",
       "  'variations_actions_changes_attributes_style': 'min-height: 450px; padding-top: 2px;',\n",
       "  'variations_actions_changes_id': '882AF443-66B1-4C4E-A7D4-28B0261D8235',\n",
       "  'variations_actions_changes_rearrange_insertSelector': '',\n",
       "  'variations_actions_changes_rearrange_operator': 'before',\n",
       "  'variations_actions_changes_selector': 'section:nth-of-type(2)',\n",
       "  'variations_actions_changes_type': 'attribute',\n",
       "  'variations_actions_page_id': 12739870165,\n",
       "  'variations_actions_share_link': 'https://pages.infusionsoft.com/25_things_to_automate_gate?optimizely_token=811545cca72276fcca59490f31b030b3990957534e1d058bc6ff5643ffd0fa23&optimizely_x=12762280184&optimizely_x_audiences=&optimizely_preview_layer_ids=12747070594&optimizely_snippet=s3-10427612860',\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Variation #1',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 12762280184,\n",
       "  'variations_weight': 5000}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing flatten_dupe_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_flattened_test = flatten_dupe_vals(vals=test, key='actions')\n",
    "vals = test\n",
    "key = 'actions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duped_results = []\n",
    "for element in vals[key]:\n",
    "    ts_dict = populating_vals(outer_dict=vals, inner_flattened_list=element, destination_key=key)\n",
    "    duped_results.append(ts_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_results = []\n",
    "for element in duped_results:\n",
    "    flattened_results.append(flatten(element, {}, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten(duped_results[0], {}, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is the flatten function that f*cked things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duped_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected flatten\n",
    "def flatten(jayson, acc, prefix):\n",
    "    if isinstance(jayson, dict):\n",
    "        for k,v in jayson.items():\n",
    "            if prefix:\n",
    "                prefix_k = prefix + \"_\" + k\n",
    "            else: \n",
    "                prefix_k = k\n",
    "            prefix_k = prefix_k.replace('-', '_')\n",
    "            \n",
    "            if isinstance(v, dict):\n",
    "                flatten(v, acc, prefix_k)\n",
    "            elif isinstance(v, list):\n",
    "                if v != []:\n",
    "                    for j in v:\n",
    "                        flatten(j, acc, prefix_k)\n",
    "                else:\n",
    "                    acc[prefix_k] = v\n",
    "            else:\n",
    "                acc[prefix_k] = v\n",
    "        return acc \n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten(duped_results[0], {}, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus fixing the missing changes issue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_variations = []\n",
    "\n",
    "for var in expanded_exp['variations']:\n",
    "    flattened_actions = []\n",
    "    for action in var['actions']:\n",
    "        print(action)\n",
    "#         flattened_changes = []\n",
    "#         for element in action['changes']:\n",
    "#             flattened_changes.append(element)\n",
    "\n",
    "        # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "#         updated_changes = populating_vals(outer_dict=action, inner_flattened_list=flattened_changes, destination_key='changes')\n",
    "#         new_flattened_changes = flatten_dupe_vals(vals=updated_changes, key='changes')\n",
    "\n",
    "#     update_actions = populating_vals(outer_dict=var, inner_flattened_list=new_flattened_changes, destination_key='actions')\n",
    "#     flattened_actions.extend(flatten_dupe_vals(vals=update_actions, key='actions'))  \n",
    "\n",
    "# update_variations = populating_vals(outer_dict=expanded_exp, inner_flattened_list=flattened_actions, destination_key='variations')\n",
    "# flattened_variations.extend(flatten_dupe_vals(vals=update_variations, key='variations'))\n",
    "\n",
    "# expanded_variations = flattened_variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiment_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of no results\n",
    "# result_endpoint = 'https://api.optimizely.com/v2/experiments/11479333433/timeseries'\n",
    "# example of normal time series\n",
    "result_endpoint = 'https://api.optimizely.com/v2/experiments/11477653122/timeseries'\n",
    "# example of \n",
    "# result_endpoint = f'https://api.optimizely.com/v2/experiments/{experiment_id}/timeseries'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ts = requests.get(result_endpoint, headers=headers)\n",
    "\n",
    "# if '' then the experiment has not started yet\n",
    "if response_ts.text == '':\n",
    "    j_ts = {'experiment_id': experiment_id}\n",
    "elif 'bad' in response_ts.text:\n",
    "    j_ts = {'experiment_id': experiment_id}\n",
    "else:\n",
    "    j_ts = json.loads(response_ts.text)\n",
    "\n",
    "new_j_ts = pope.fix_json_values(callback=fix_values, obj=j_ts, reset_key='results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_j_ts = []\n",
    "\n",
    "flattened_metrics = []\n",
    "for metric in new_j_ts['metrics']:\n",
    "    if 'results' in metric.keys():\n",
    "        for ts in metric['results']:\n",
    "            flattened_timeseries = []\n",
    "            for element in ts['timeseries']:\n",
    "                element['upload_ts'] = str(datetime.now())\n",
    "                flattened_timeseries.append(flatten(element, {}, ''))\n",
    "\n",
    "            # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "            updated_results = populating_vals(outer_dict=ts, inner_flattened_list=flattened_timeseries, destination_key='timeseries')\n",
    "            flattened_results = flatten_dupe_vals(vals=updated_results, key='timeseries')\n",
    "\n",
    "        # Replace old 'metrics' with new 'flattened_results'\n",
    "        update_metrics = populating_vals(outer_dict=metric, inner_flattened_list=flattened_results, destination_key='results')\n",
    "        flattened_metrics.extend(flatten_dupe_vals(vals=update_metrics, key='results'))\n",
    "\n",
    "    else:\n",
    "        flattened_metrics = [flatten(new_j_ts, {}, '')]\n",
    "\n",
    "update_new_j_ts = populating_vals(outer_dict=new_j_ts, inner_flattened_list=flattened_metrics, destination_key='metrics')\n",
    "flattened_j_ts.extend(flatten_dupe_vals(vals=update_new_j_ts, key='metrics'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_j_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_j_ts['metrics']\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_original import read_endpoint, generate_projects, generate_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get('GOOGLE_ACCOUNT_CREDENTIALS'):\n",
    "    os.environ['GOOGLE_ACCOUNT_CREDENTIALS'] = '/home/engineering/keyfile.json'\n",
    "gbq_key = os.environ.get('GOOGLE_ACCOUNT_CREDENTIALS')\n",
    "\n",
    "############################################### Instantiating Popelines #######################################\n",
    "pope = popelines.popeline(dataset_id='optimizely', service_key_file_loc=gbq_key, directory='.', verbose=False)\n",
    "\n",
    "# Optimizely parameters\n",
    "headers = {\n",
    "    'Authorization': 'Bearer 2:EWAWmaXb4TgtYVU2VvwoEF-9UbJxBahkiFh1633_Oc9nmju7iJis',\n",
    "}\n",
    "\n",
    "# endpoints\n",
    "project_endpoint = 'https://api.optimizely.com/v2/projects'\n",
    "experiment_endpoint = 'https://api.optimizely.com/v2/experiments'\n",
    "\n",
    "\n",
    "############################################### generate and upload all projects ##############################\n",
    "all_projects = generate_projects(project_endpoint, headers)\n",
    "for project in all_projects:\n",
    "    project['upload_ts'] = str(datetime.now())\n",
    "\n",
    "# upload projects \n",
    "pope.write_to_json(file_name='../uploads/projects.json', jayson=all_projects, mode='w')\n",
    "pope.write_to_bq(table_name='projects', file_name='../uploads/projects.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "\n",
    "\n",
    "############################################### generate and upload all experiments ##############################\n",
    "# get a list of project_id from all_projects\n",
    "project_id_list = []\n",
    "for project in all_projects:\n",
    "    project_id_list.append(project['id'])\n",
    "\n",
    "# to accumulate all experiment_id, for \n",
    "experiment_id_list = []\n",
    "origin_single_table = []\n",
    "origin_metrics_table = []\n",
    "origin_variations_table = []\n",
    "\n",
    "# loop over all project_id_list to get experiments within each project\n",
    "for project_id in project_id_list:\n",
    "    # params include project_id (required) and experiments pulling per each request (default only 25)\n",
    "    params = (\n",
    "        ('project_id', project_id),\n",
    "        ('per_page', 100),\n",
    "    ) \n",
    "\n",
    "    exp_list = read_endpoint(endpoint=experiment_endpoint, headers_set=headers, params_set=params)\n",
    "    exp_id_list = []\n",
    "    for exp in exp_list:\n",
    "        exp_id_list.append(exp['id'])\n",
    "    experiment_id_list.extend(exp_id_list)\n",
    "\n",
    "    all_singles, metrics_table, variations_table = generate_experiments(exp_list)\n",
    "    origin_single_table.extend(all_singles)\n",
    "    origin_metrics_table.extend(metrics_table)\n",
    "    origin_variations_table.extend(variations_table)\n",
    "\n",
    "pope.write_to_json(file_name='../uploads/origin_experiments_single_fields.json', jayson=origin_single_table, mode='w')  \n",
    "pope.write_to_json(file_name='../uploads/origin_experiments_metrics_table.json', jayson=origin_metrics_table, mode='w')\n",
    "pope.write_to_json(file_name='../uploads/origin_experiments_variations_table.json', jayson=origin_variations_table, mode='w')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in origin_single_table:\n",
    "    if e['id'] == 12900000180:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in origin_metrics_table:\n",
    "    if m['experiment_id'] == 12900000180:\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for v in origin_variations_table:\n",
    "    if v['experiment_id'] == 12900000180:\n",
    "        l.append(v['variations_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in exp_list:\n",
    "    print(e['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations = {}\n",
    "variations['experiment_id'] = exp['id']\n",
    "variations['variations'] = exp['variations']\n",
    "\n",
    "flattened_variations = []\n",
    "\n",
    "for var in exp['variations']:\n",
    "    flattened_actions = []\n",
    "    if len(var['actions']) > 0:\n",
    "        for action in var['actions']:\n",
    "            flattened_changes = []\n",
    "            for element in action['changes']:\n",
    "                flattened_changes.append(element)\n",
    "            # Replace old 'changes' with new 'flattened_changes'\n",
    "            updated_changes = populating_vals(outer_dict=action, inner_flattened_list=flattened_changes, destination_key='changes')\n",
    "            new_flattened_changes = flatten_dupe_vals(vals=updated_changes, key='changes')\n",
    "\n",
    "        update_actions = populating_vals(outer_dict=var, inner_flattened_list=new_flattened_changes, destination_key='actions')\n",
    "        flat = flatten_dupe_vals(vals=update_actions, key='actions')\n",
    "        \n",
    "        flattened_actions.extend(flat)\n",
    "\n",
    "    else:\n",
    "        other_flat = {}\n",
    "        for k,v in var.items():\n",
    "            if k != 'actions':\n",
    "                other_flat['actions'] = []\n",
    "                other_flat[k] = v\n",
    "        flat = [other_flat]\n",
    "    \n",
    "        flattened_actions.extend(flat)\n",
    "\n",
    "    update_variations = populating_vals(outer_dict=variations, inner_flattened_list=flattened_actions, destination_key='variations')\n",
    "    flattened_variations.extend(flatten_dupe_vals(vals=update_variations, key='variations'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(flattened_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in flattened_variations:\n",
    "    print(v['variations_variation_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in flattened_variations:\n",
    "    print(v['variations_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in flattened_variations:\n",
    "    if 'variations_actions_changes_id' in v.keys():\n",
    "        print(v['variations_actions_changes_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
