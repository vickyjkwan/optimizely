{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import popelines\n",
    "import os\n",
    "from main import fix_values, populating_vals, flatten, flatten_dupe_vals\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_values(value, key, reset_key):\n",
    "    if key == reset_key:\n",
    "        new_list = []\n",
    "        for x in value:\n",
    "            value[x][f'{reset_key}_id'] = x\n",
    "            new_list.append(value[x])\n",
    "        return new_list\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read endpoint, returns a json file of the HTTP request\n",
    "def read_endpoint(endpoint, headers_set, params_set=None):\n",
    "    try:\n",
    "        response = requests.get(endpoint, headers=headers_set, params=params_set)\n",
    "        response_text = json.loads(response.text)\n",
    "        response.raise_for_status()\n",
    "\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate all experiments given a project id\n",
    "# def generate_experiments(project_id, experiment_endpoint, experiment_headers, experiment_params):\n",
    "#     # get all experiments from one project\n",
    "#     j_exp = read_endpoint(endpoint=experiment_endpoint, headers_set=experiment_headers, params_set=experiment_params)\n",
    "\n",
    "#     # loop for all experiments in this project\n",
    "# #     experiment_id_list = []\n",
    "# #     upload_exp_list = []\n",
    "# #     for exp in j_exp:\n",
    "# #         exp['project_id'] = project_id\n",
    "# #         upload_exp_list.append(flatten(exp, {}, ''))\n",
    "# #         experiment_id_list.append(exp['id'])\n",
    "        \n",
    "#     return upload_exp_list, experiment_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate all projects within account\n",
    "def generate_projects(project_endpoint, project_headers):\n",
    "    # get all projects\n",
    "    j_proj = read_endpoint(endpoint=project_endpoint, headers_set=project_headers)\n",
    "\n",
    "    # store a list of project metadata\n",
    "    return j_proj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all projects, get project_id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbq_key = os.environ.get('GOOGLE_ACCOUNT_CREDENTIALS')\n",
    "pope = popelines.popeline(dataset_id='optimizely', service_key_file_loc=gbq_key, directory='.', verbose=False)\n",
    "\n",
    "# Optimizely parameters\n",
    "headers = {\n",
    "    'Authorization': 'Bearer 2:EWAWmaXb4TgtYVU2VvwoEF-9UbJxBahkiFh1633_Oc9nmju7iJis',\n",
    "    'Content-Type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_endpoint = 'https://api.optimizely.com/v2/projects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects = generate_projects(project_endpoint, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pope.write_to_json(file_name='../uploads/projects.json', jayson=all_projects, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pope.write_to_bq(table_name='projects', file_name='../uploads/projects.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "# print(\"Successfully uploaded all projects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_list = []\n",
    "for project in all_projects:\n",
    "    project_id_list.append((project['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_id_name = []\n",
    "# for project in all_projects:\n",
    "#     project_id_name.append((project['id'], project['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_id_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_endpoint = 'https://api.optimizely.com/v2/experiments'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_id_list = []\n",
    "# all_exp_list = []\n",
    "\n",
    "# for project_id in project_id_list:\n",
    "    # params include project_id (required) and experiments pulling per each request (default only 25)\n",
    "params = (\n",
    "    ('project_id', 9965963792),\n",
    "    ('per_page', 100),\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_list = read_endpoint(endpoint=experiment_endpoint, headers_set=headers, params_set=params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_id_list = []\n",
    "for exp in exp_list:\n",
    "    exp_id_list.append(exp['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id_list.extend(exp_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in exp_list:\n",
    "    if e['id'] == 11039523400:\n",
    "        new = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allocation_policy': 'manual',\n",
       " 'audience_conditions': 'everyone',\n",
       " 'campaign_id': 11041413439,\n",
       " 'changes': [],\n",
       " 'created': '2018-07-07T22:18:03.362400Z',\n",
       " 'description': 'Switching \"Email\" field to say \"Company Email\" - will lead quality increase and will form conversion be impacted?',\n",
       " 'earliest': '2018-07-07T22:25:27.209360Z',\n",
       " 'holdback': 0,\n",
       " 'id': 11039523400,\n",
       " 'is_classic': False,\n",
       " 'last_modified': '2018-07-10T15:45:19.606040Z',\n",
       " 'latest': '2018-07-08T18:29:55.140960Z',\n",
       " 'metrics': [{'aggregator': 'unique',\n",
       "   'event_id': 10757331770,\n",
       "   'scope': 'visitor',\n",
       "   'winning_direction': 'increasing'},\n",
       "  {'aggregator': 'unique',\n",
       "   'event_id': 10601774395,\n",
       "   'scope': 'visitor',\n",
       "   'winning_direction': 'increasing'},\n",
       "  {'aggregator': 'sum',\n",
       "   'field': 'revenue',\n",
       "   'scope': 'visitor',\n",
       "   'winning_direction': 'increasing'}],\n",
       " 'name': 'FT Sign Up Company Email Field July 7',\n",
       " 'page_ids': [11094440334],\n",
       " 'project_id': 9965963792,\n",
       " 'status': 'paused',\n",
       " 'type': 'a/b',\n",
       " 'variations': [{'actions': [],\n",
       "   'archived': False,\n",
       "   'name': 'Label says \"Email\"',\n",
       "   'status': 'active',\n",
       "   'variation_id': 11059362372,\n",
       "   'weight': 3333},\n",
       "  {'actions': [],\n",
       "   'archived': False,\n",
       "   'name': 'Label says \"Company Email\"',\n",
       "   'status': 'active',\n",
       "   'variation_id': 11064823629,\n",
       "   'weight': 3333},\n",
       "  {'actions': [],\n",
       "   'archived': False,\n",
       "   'name': 'Label says \"Business Email\"',\n",
       "   'status': 'active',\n",
       "   'variation_id': 11047562271,\n",
       "   'weight': 3334}]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_singles = []\n",
    "nested_key_list = []\n",
    "for k,v in exp.items():\n",
    "    if isinstance(v, list):\n",
    "        nested_key_list.append(k)\n",
    "\n",
    "single_layer_experiment = {}    \n",
    "for k,v in exp.items():\n",
    "    if k not in nested_key_list:\n",
    "        k = k.replace('-', '_')\n",
    "        single_layer_experiment[k] = exp[k]\n",
    "single_layer_experiment['upload_ts'] = str(datetime.now())\n",
    "\n",
    "\n",
    "all_singles.append(flatten(single_layer_experiment, {}, ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'allocation_policy': 'manual',\n",
       "  'audience_conditions': 'everyone',\n",
       "  'campaign_id': 11041413439,\n",
       "  'created': '2018-07-07T22:18:03.362400Z',\n",
       "  'description': 'Switching \"Email\" field to say \"Company Email\" - will lead quality increase and will form conversion be impacted?',\n",
       "  'earliest': '2018-07-07T22:25:27.209360Z',\n",
       "  'holdback': 0,\n",
       "  'id': 11039523400,\n",
       "  'is_classic': False,\n",
       "  'last_modified': '2018-07-10T15:45:19.606040Z',\n",
       "  'latest': '2018-07-08T18:29:55.140960Z',\n",
       "  'name': 'FT Sign Up Company Email Field July 7',\n",
       "  'project_id': 9965963792,\n",
       "  'status': 'paused',\n",
       "  'type': 'a/b',\n",
       "  'upload_ts': '2019-02-20 15:05:27.285798'}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'allocation_policy': 'manual', 'audience_conditions': 'everyone', 'campaign_id': 11041413439, 'created': '2018-07-07T22:18:03.362400Z', 'description': 'Switching \"Email\" field to say \"Company Email\" - will lead quality increase and will form conversion be impacted?', 'earliest': '2018-07-07T22:25:27.209360Z', 'holdback': 0, 'id': 11039523400, 'is_classic': False, 'last_modified': '2018-07-10T15:45:19.606040Z', 'latest': '2018-07-08T18:29:55.140960Z', 'metrics_aggregator': 'unique', 'metrics_event_id': 10757331770, 'metrics_scope': 'visitor', 'metrics_winning_direction': 'increasing', 'name': 'FT Sign Up Company Email Field July 7', 'project_id': 9965963792, 'status': 'paused', 'type': 'a/b', 'variations_archived': False, 'variations_name': 'Label says \"Business Email\"', 'variations_status': 'active', 'variations_variation_id': 11047562271, 'variations_weight': 3334}\n",
      "{'allocation_policy': 'manual', 'audience_conditions': 'everyone', 'campaign_id': 11041413439, 'created': '2018-07-07T22:18:03.362400Z', 'description': 'Switching \"Email\" field to say \"Company Email\" - will lead quality increase and will form conversion be impacted?', 'earliest': '2018-07-07T22:25:27.209360Z', 'holdback': 0, 'id': 11039523400, 'is_classic': False, 'last_modified': '2018-07-10T15:45:19.606040Z', 'latest': '2018-07-08T18:29:55.140960Z', 'metrics_aggregator': 'unique', 'metrics_event_id': 10601774395, 'metrics_scope': 'visitor', 'metrics_winning_direction': 'increasing', 'name': 'FT Sign Up Company Email Field July 7', 'project_id': 9965963792, 'status': 'paused', 'type': 'a/b', 'variations_archived': False, 'variations_name': 'Label says \"Business Email\"', 'variations_status': 'active', 'variations_variation_id': 11047562271, 'variations_weight': 3334}\n",
      "{'allocation_policy': 'manual', 'audience_conditions': 'everyone', 'campaign_id': 11041413439, 'created': '2018-07-07T22:18:03.362400Z', 'description': 'Switching \"Email\" field to say \"Company Email\" - will lead quality increase and will form conversion be impacted?', 'earliest': '2018-07-07T22:25:27.209360Z', 'holdback': 0, 'id': 11039523400, 'is_classic': False, 'last_modified': '2018-07-10T15:45:19.606040Z', 'latest': '2018-07-08T18:29:55.140960Z', 'metrics_aggregator': 'sum', 'metrics_field': 'revenue', 'metrics_scope': 'visitor', 'metrics_winning_direction': 'increasing', 'name': 'FT Sign Up Company Email Field July 7', 'project_id': 9965963792, 'status': 'paused', 'type': 'a/b', 'variations_archived': False, 'variations_name': 'Label says \"Business Email\"', 'variations_status': 'active', 'variations_variation_id': 11047562271, 'variations_weight': 3334}\n"
     ]
    }
   ],
   "source": [
    "# nested part into separate tables:\n",
    "# metrics table:\n",
    " \n",
    "flattened_metric = []\n",
    "for element in exp['metrics']:\n",
    "    flattened_metric.append(element)\n",
    "\n",
    "updated_metric = populating_vals(outer_dict=exp, inner_flattened_list=flattened_metric, destination_key='metrics')\n",
    "new_flattened_metric = flatten_dupe_vals(vals=updated_metric, key='metrics')\n",
    "\n",
    "metric_list = []\n",
    "# for metric in new_flattened_metric:\n",
    "#     print(metric)\n",
    "#     metric_dict = {}\n",
    "#     metric_dict['metrics_aggregator'] = metric['metrics_aggregator']\n",
    "#     metric_dict['metrics_event_id'] = metric['metrics_event_id']\n",
    "#     metric_dict['metrics_scope'] =  metric['metrics_scope']\n",
    "#     metric_dict['metrics_winning_direction'] = metric['metrics_winning_direction']\n",
    "#     metric_dict['experiment_id'] = exp['id']\n",
    "#     metric_dict['upload_ts'] = str(datetime.now())\n",
    "#     metric_list.append(metric_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'allocation_policy': 'manual',\n",
       "  'audience_conditions': 'everyone',\n",
       "  'campaign_id': 11041413439,\n",
       "  'created': '2018-07-07T22:18:03.362400Z',\n",
       "  'description': 'Switching \"Email\" field to say \"Company Email\" - will lead quality increase and will form conversion be impacted?',\n",
       "  'earliest': '2018-07-07T22:25:27.209360Z',\n",
       "  'holdback': 0,\n",
       "  'id': 11039523400,\n",
       "  'is_classic': False,\n",
       "  'last_modified': '2018-07-10T15:45:19.606040Z',\n",
       "  'latest': '2018-07-08T18:29:55.140960Z',\n",
       "  'metrics_aggregator': 'unique',\n",
       "  'metrics_event_id': 10757331770,\n",
       "  'metrics_scope': 'visitor',\n",
       "  'metrics_winning_direction': 'increasing',\n",
       "  'name': 'FT Sign Up Company Email Field July 7',\n",
       "  'project_id': 9965963792,\n",
       "  'status': 'paused',\n",
       "  'type': 'a/b',\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Label says \"Business Email\"',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 11047562271,\n",
       "  'variations_weight': 3334},\n",
       " {'allocation_policy': 'manual',\n",
       "  'audience_conditions': 'everyone',\n",
       "  'campaign_id': 11041413439,\n",
       "  'created': '2018-07-07T22:18:03.362400Z',\n",
       "  'description': 'Switching \"Email\" field to say \"Company Email\" - will lead quality increase and will form conversion be impacted?',\n",
       "  'earliest': '2018-07-07T22:25:27.209360Z',\n",
       "  'holdback': 0,\n",
       "  'id': 11039523400,\n",
       "  'is_classic': False,\n",
       "  'last_modified': '2018-07-10T15:45:19.606040Z',\n",
       "  'latest': '2018-07-08T18:29:55.140960Z',\n",
       "  'metrics_aggregator': 'unique',\n",
       "  'metrics_event_id': 10601774395,\n",
       "  'metrics_scope': 'visitor',\n",
       "  'metrics_winning_direction': 'increasing',\n",
       "  'name': 'FT Sign Up Company Email Field July 7',\n",
       "  'project_id': 9965963792,\n",
       "  'status': 'paused',\n",
       "  'type': 'a/b',\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Label says \"Business Email\"',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 11047562271,\n",
       "  'variations_weight': 3334},\n",
       " {'allocation_policy': 'manual',\n",
       "  'audience_conditions': 'everyone',\n",
       "  'campaign_id': 11041413439,\n",
       "  'created': '2018-07-07T22:18:03.362400Z',\n",
       "  'description': 'Switching \"Email\" field to say \"Company Email\" - will lead quality increase and will form conversion be impacted?',\n",
       "  'earliest': '2018-07-07T22:25:27.209360Z',\n",
       "  'holdback': 0,\n",
       "  'id': 11039523400,\n",
       "  'is_classic': False,\n",
       "  'last_modified': '2018-07-10T15:45:19.606040Z',\n",
       "  'latest': '2018-07-08T18:29:55.140960Z',\n",
       "  'metrics_aggregator': 'sum',\n",
       "  'metrics_field': 'revenue',\n",
       "  'metrics_scope': 'visitor',\n",
       "  'metrics_winning_direction': 'increasing',\n",
       "  'name': 'FT Sign Up Company Email Field July 7',\n",
       "  'project_id': 9965963792,\n",
       "  'status': 'paused',\n",
       "  'type': 'a/b',\n",
       "  'variations_archived': False,\n",
       "  'variations_name': 'Label says \"Business Email\"',\n",
       "  'variations_status': 'active',\n",
       "  'variations_variation_id': 11047562271,\n",
       "  'variations_weight': 3334}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_flattened_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiment 10756790433\n",
      "Processing experiment 10796678057\n",
      "Processing experiment 10800885728\n",
      "Processing experiment 10815382176\n",
      "Processing experiment 10945903729\n",
      "Processing experiment 10955300529\n",
      "Processing experiment 11039523400\n",
      "Processing experiment 11938601024\n",
      "Processing experiment 11966791385\n",
      "Processing experiment 11992110033\n"
     ]
    }
   ],
   "source": [
    "metrics_table = []\n",
    "for exp in exp_list:\n",
    "    print(f\"Processing experiment {exp['id']}\")\n",
    "\n",
    "    # single layer fields:\n",
    "    nested_key_list = []\n",
    "    for k,v in exp.items():\n",
    "        if isinstance(v, list) or isinstance(v, dict):\n",
    "            nested_key_list.append(k)\n",
    "\n",
    "    single_layer_experiment = {}    \n",
    "    for k,v in exp.items():\n",
    "        if k not in nested_key_list:\n",
    "            k = k.replace('-', '_')\n",
    "            single_layer_experiment[k] = exp[k]\n",
    "    single_layer_experiment['upload_ts'] = str(datetime.now())\n",
    "\n",
    "    all_singles.append(flatten(single_layer_experiment, {}, ''))\n",
    "\n",
    "    # nested part into separate tables:\n",
    "    # metrics table:\n",
    "\n",
    "    flattened_metric = []\n",
    "    for element in exp['metrics']:\n",
    "        flattened_metric.append(element)\n",
    "\n",
    "    updated_metric = populating_vals(outer_dict=exp, inner_flattened_list=flattened_metric, destination_key='metrics')\n",
    "    new_flattened_metric = flatten_dupe_vals(vals=updated_metric, key='metrics')\n",
    "\n",
    "    metric_list = []\n",
    "    for metric in new_flattened_metric:\n",
    "        metric_dict = {}\n",
    "        metric_dict['metrics_aggregator'] = metric['metrics_aggregator']\n",
    "        if 'metrics_event_id' in metric.keys():\n",
    "            metric_dict['metrics_event_id'] = metric['metrics_event_id']\n",
    "        metric_dict['metrics_scope'] =  metric['metrics_scope']\n",
    "        metric_dict['metrics_winning_direction'] = metric['metrics_winning_direction']\n",
    "        metric_dict['experiment_id'] = exp['id']\n",
    "        metric_dict['upload_ts'] = str(datetime.now())\n",
    "        metric_list.append(metric_dict)\n",
    "        \n",
    "    metrics_table.extend(metric_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing experiment 10756790433\n",
      "Processing experiment 10756790433\n",
      "Processing experiment 10796678057\n",
      "Processing experiment 10796678057\n",
      "Processing experiment 10800885728\n",
      "Processing experiment 10800885728\n",
      "Processing experiment 10815382176\n",
      "Processing experiment 10815382176\n",
      "Processing experiment 10945903729\n",
      "Processing experiment 10945903729\n",
      "Processing experiment 10955300529\n",
      "Processing experiment 10955300529\n",
      "Processing experiment 11039523400\n",
      "Processing experiment 11039523400\n",
      "Processing experiment 11938601024\n",
      "Processing experiment 11938601024\n",
      "Processing experiment 11966791385\n",
      "Processing experiment 11966791385\n",
      "Processing experiment 11992110033\n",
      "Processing experiment 11992110033\n"
     ]
    }
   ],
   "source": [
    "variations_table = []\n",
    "for exp in exp_list:\n",
    "    print(f\"Processing experiment {exp['id']}\")\n",
    "\n",
    "    variations = {}\n",
    "    # for exp in exp_list:\n",
    "\n",
    "    print(f\"Processing experiment {exp['id']}\")\n",
    "\n",
    "    variations['experiment_id'] = exp['id']\n",
    "    variations['variations'] = exp['variations']\n",
    "\n",
    "    flattened_variations = []\n",
    "\n",
    "    for var in exp['variations']:\n",
    "        flattened_actions = []\n",
    "        if len(var['actions']) > 0:\n",
    "            for action in var['actions']:\n",
    "                flattened_changes = []\n",
    "                for element in action['changes']:\n",
    "                    flattened_changes.append(element)\n",
    "                # Replace old 'changes' with new 'flattened_changes'\n",
    "                updated_changes = populating_vals(outer_dict=action, inner_flattened_list=flattened_changes, destination_key='changes')\n",
    "                new_flattened_changes = flatten_dupe_vals(vals=updated_changes, key='changes')\n",
    "\n",
    "                update_actions = populating_vals(outer_dict=var, inner_flattened_list=new_flattened_changes, destination_key='actions')\n",
    "                flat = flatten_dupe_vals(vals=update_actions, key='actions')\n",
    "                flattened_actions.extend(flat)\n",
    "\n",
    "        else:\n",
    "            other_flat = {}\n",
    "            for k,v in var.items():\n",
    "                if k != 'actions':\n",
    "                    other_flat['actions'] = []\n",
    "                    other_flat[k] = v\n",
    "            flat = [other_flat]\n",
    "            flattened_actions.extend(flat)\n",
    "\n",
    "        update_variations = populating_vals(outer_dict=variations, inner_flattened_list=flattened_actions, destination_key='variations')\n",
    "        flattened_variations.extend(flatten_dupe_vals(vals=update_variations, key='variations'))\n",
    "\n",
    "    variations_table.extend(flattened_variations)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carousel\n",
      "No Carousel\n"
     ]
    }
   ],
   "source": [
    "for v in variations_table:\n",
    "    if v['experiment_id'] == 10945903729:\n",
    "        print(v['variations_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'actions': [],\n",
       "  'archived': False,\n",
       "  'name': 'Original',\n",
       "  'status': 'active',\n",
       "  'variation_id': 11994110041,\n",
       "  'weight': 5000},\n",
       " {'actions': [{'changes': [{'async': False,\n",
       "      'attributes': {'href': 'https://freetrial.infusionsoft.com/signup/2'},\n",
       "      'css': {},\n",
       "      'dependencies': [],\n",
       "      'id': 'CAE0BD33-7160-429C-BA16-A6A7E73F558A',\n",
       "      'rearrange': {'insertSelector': '', 'operator': 'before'},\n",
       "      'selector': '.homepage-hero-ft-cta',\n",
       "      'type': 'attribute'}],\n",
       "    'page_id': 11933141690,\n",
       "    'share_link': 'http://www.infusionsoft.com?optimizely_token=1023b14998b0975f176cb8cf234dca953e6cb5016d957a058d1a8c7652d7d3fc&optimizely_x=11970581627&optimizely_x_audiences=&optimizely_preview_layer_ids=11935062681&optimizely_snippet=s3-9965963792'}],\n",
       "  'archived': False,\n",
       "  'name': 'Redirect FT CTA to freetrial.infusionsoft.com/signup/2',\n",
       "  'status': 'active',\n",
       "  'variation_id': 11970581627,\n",
       "  'weight': 5000}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp['variations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_type': 'url_changed',\n",
       " 'conditions': '[\"and\", [\"or\", {\"match_type\": \"simple\", \"type\": \"url\", \"value\": \"freetrial.infusionsoft.com/setup\"}, {\"match_type\": \"simple\", \"type\": \"url\", \"value\": \"freetrial.infusionsoft.com/signup\"}]]',\n",
       " 'edit_url': 'freetrial.infusionsoft.com/setup',\n",
       " 'key': '9965963792_url_targeting_for_ft_signup_variations',\n",
       " 'page_id': 10752650977}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp['url_targeting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_id': 10756790433,\n",
       " 'url_targeting_activation_type': 'url_changed',\n",
       " 'url_targeting_conditions': '[\"and\", [\"or\", {\"match_type\": \"simple\", \"type\": \"url\", \"value\": \"freetrial.infusionsoft.com/setup\"}, {\"match_type\": \"simple\", \"type\": \"url\", \"value\": \"freetrial.infusionsoft.com/signup\"}]]',\n",
       " 'url_targeting_edit_url': 'freetrial.infusionsoft.com/setup',\n",
       " 'url_targeting_key': '9965963792_url_targeting_for_ft_signup_variations',\n",
       " 'url_targeting_page_id': 10752650977}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expanded_exp['experiment_id'] = exp['id']\n",
    "# expanded_exp['variations'] = exp['variations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_variations = []\n",
    "\n",
    "for var in expanded_exp['variations']:\n",
    "    flattened_actions = []\n",
    "    for action in var['actions']:\n",
    "        print(action)\n",
    "#         flattened_changes = []\n",
    "#         for element in action['changes']:\n",
    "#             flattened_changes.append(element)\n",
    "\n",
    "        # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "#         updated_changes = populating_vals(outer_dict=action, inner_flattened_list=flattened_changes, destination_key='changes')\n",
    "#         new_flattened_changes = flatten_dupe_vals(vals=updated_changes, key='changes')\n",
    "\n",
    "#     update_actions = populating_vals(outer_dict=var, inner_flattened_list=new_flattened_changes, destination_key='actions')\n",
    "#     flattened_actions.extend(flatten_dupe_vals(vals=update_actions, key='actions'))  \n",
    "\n",
    "# update_variations = populating_vals(outer_dict=expanded_exp, inner_flattened_list=flattened_actions, destination_key='variations')\n",
    "# flattened_variations.extend(flatten_dupe_vals(vals=update_variations, key='variations'))\n",
    "\n",
    "# expanded_variations = flattened_variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One table for all single layer fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_key_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in exp_list[0].items():\n",
    "    if isinstance(v, list) or isinstance(v, dict):\n",
    "        nested_key_list.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_layer_experiment = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in exp_list[0].items():\n",
    "    if k not in nested_key_list:\n",
    "        single_layer_experiment[k] = exp_list[0][k]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_layer_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_singles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_singles.append(single_layer_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_singles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand nested part manually into separate tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_j_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in j_exp:\n",
    "\n",
    "    expanded_exp = {}\n",
    "    \n",
    "    expanded_exp['experiment_id'] = exp['id']\n",
    "    expanded_exp['changes'] = exp['changes']\n",
    "\n",
    "    expanded_metrics = {}\n",
    "    expanded_metrics['experiment_id'] = exp['id']\n",
    "    expanded_metrics['metrics'] = exp['metrics']\n",
    "    expanded_exp['metrics'] = flatten_dupe_vals(vals=expanded_metrics, key='metrics')\n",
    "\n",
    "    if 'url_targeting' in exp.keys():\n",
    "        expanded_exp['experiment_id'] = exp['id']\n",
    "        expanded_exp['url_targeting'] = exp['url_targeting']\n",
    "        expanded_exp = flatten(expanded_exp, {}, '')\n",
    "    \n",
    "    expanded_exp['experiment_id'] = exp['id']\n",
    "    expanded_exp['variations'] = exp['variations']\n",
    "    \n",
    "    flattened_variations = []\n",
    "    \n",
    "    for var in expanded_exp['variations']:\n",
    "        flattened_actions = []\n",
    "        for action in var['actions']:\n",
    "            flattened_changes = []\n",
    "            for element in action['changes']:\n",
    "                flattened_changes.append(element)\n",
    "\n",
    "            # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "            updated_changes = populating_vals(outer_dict=action, inner_flattened_list=flattened_changes, destination_key='changes')\n",
    "            new_flattened_changes = flatten_dupe_vals(vals=updated_changes, key='changes')\n",
    "\n",
    "        update_actions = populating_vals(outer_dict=var, inner_flattened_list=new_flattened_changes, destination_key='actions')\n",
    "        flattened_actions.extend(flatten_dupe_vals(vals=update_actions, key='actions'))  \n",
    "\n",
    "    update_variations = populating_vals(outer_dict=expanded_exp, inner_flattened_list=flattened_actions, destination_key='variations')\n",
    "    flattened_variations.extend(flatten_dupe_vals(vals=update_variations, key='variations'))\n",
    "    \n",
    "    expanded_variations = flattened_variations\n",
    "    \n",
    "    expanded_exp = expanded_variations\n",
    "    expanded_j_list.extend(expanded_exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(expanded_j_list[12]['variations_actions_changes_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiment_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of no results\n",
    "# result_endpoint = 'https://api.optimizely.com/v2/experiments/11479333433/timeseries'\n",
    "# example of normal time series\n",
    "result_endpoint = 'https://api.optimizely.com/v2/experiments/11477653122/timeseries'\n",
    "# example of \n",
    "# result_endpoint = f'https://api.optimizely.com/v2/experiments/{experiment_id}/timeseries'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ts = requests.get(result_endpoint, headers=headers)\n",
    "\n",
    "# if '' then the experiment has not started yet\n",
    "if response_ts.text == '':\n",
    "    j_ts = {'experiment_id': experiment_id}\n",
    "elif 'bad' in response_ts.text:\n",
    "    j_ts = {'experiment_id': experiment_id}\n",
    "else:\n",
    "    j_ts = json.loads(response_ts.text)\n",
    "\n",
    "new_j_ts = pope.fix_json_values(callback=fix_values, obj=j_ts, reset_key='results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_j_ts = []\n",
    "\n",
    "flattened_metrics = []\n",
    "for metric in new_j_ts['metrics']:\n",
    "    if 'results' in metric.keys():\n",
    "        for ts in metric['results']:\n",
    "            flattened_timeseries = []\n",
    "            for element in ts['timeseries']:\n",
    "                element['upload_ts'] = str(datetime.now())\n",
    "                flattened_timeseries.append(flatten(element, {}, ''))\n",
    "\n",
    "            # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "            updated_results = populating_vals(outer_dict=ts, inner_flattened_list=flattened_timeseries, destination_key='timeseries')\n",
    "            flattened_results = flatten_dupe_vals(vals=updated_results, key='timeseries')\n",
    "\n",
    "        # Replace old 'metrics' with new 'flattened_results'\n",
    "        update_metrics = populating_vals(outer_dict=metric, inner_flattened_list=flattened_results, destination_key='results')\n",
    "        flattened_metrics.extend(flatten_dupe_vals(vals=update_metrics, key='results'))\n",
    "\n",
    "    else:\n",
    "        flattened_metrics = [flatten(new_j_ts, {}, '')]\n",
    "\n",
    "update_new_j_ts = populating_vals(outer_dict=new_j_ts, inner_flattened_list=flattened_metrics, destination_key='metrics')\n",
    "flattened_j_ts.extend(flatten_dupe_vals(vals=update_new_j_ts, key='metrics'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_j_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_j_ts['metrics']\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects = generate_projects(project_endpoint, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_list = []\n",
    "for project in all_projects:\n",
    "    project_id_list.append(project['id'])\n",
    "\n",
    "# to accumulate all experiment_id, for \n",
    "experiment_id_list = []\n",
    "\n",
    "expanded_exp_list = []\n",
    "all_singles = []\n",
    "# loop over all project_id_list to get experiments within each project\n",
    "for project_id in project_id_list:\n",
    "    # params include project_id (required) and experiments pulling per each request (default only 25)\n",
    "    params = (\n",
    "        ('project_id', project_id),\n",
    "        ('per_page', 100),\n",
    "    ) \n",
    "\n",
    "    exp_list = read_endpoint(endpoint=experiment_endpoint, headers_set=headers, params_set=params)\n",
    "    exp_id_list = []\n",
    "    for exp in exp_list:\n",
    "        exp_id_list.append(exp['id'])\n",
    "    experiment_id_list.extend(exp_id_list)\n",
    "\n",
    "    ###### Game plan is to separate nested fields from single layer fields, upload them to separate table, then do joins on BQ level\n",
    "#     expanded_exp_list = []\n",
    "#     all_singles = []\n",
    "\n",
    "    for exp in exp_list:\n",
    "        print(f\"Processing experiment {exp['id']}, of project {project_id}\")\n",
    "\n",
    "        # single layer fields:\n",
    "        nested_key_list = []\n",
    "        for k,v in exp.items():\n",
    "            if isinstance(v, list) or isinstance(v, dict):\n",
    "                nested_key_list.append(k)\n",
    "\n",
    "        single_layer_experiment = {}    \n",
    "        for k,v in exp.items():\n",
    "            if k not in nested_key_list:\n",
    "                k = k.replace('-', '_')\n",
    "                single_layer_experiment[k] = exp[k]\n",
    "\n",
    "        all_singles.append(single_layer_experiment)\n",
    "\n",
    "        # nested part into separate tables:\n",
    "        expanded_exp = {}\n",
    "\n",
    "        expanded_exp['experiment_id'] = exp['id']\n",
    "        expanded_exp['changes'] = exp['changes']\n",
    "\n",
    "        expanded_metrics = {}\n",
    "        expanded_metrics['experiment_id'] = exp['id']\n",
    "        expanded_metrics['metrics'] = exp['metrics']\n",
    "        expanded_exp['metrics'] = flatten_dupe_vals(vals=expanded_metrics, key='metrics')\n",
    "\n",
    "        if 'url_targeting' in exp.keys():\n",
    "            expanded_exp['experiment_id'] = exp['id']\n",
    "            expanded_exp['url_targeting'] = exp['url_targeting']\n",
    "            expanded_exp = flatten(expanded_exp, {}, '')\n",
    "\n",
    "        expanded_exp['experiment_id'] = exp['id']\n",
    "        expanded_exp['variations'] = exp['variations']\n",
    "\n",
    "        flattened_variations = []\n",
    "\n",
    "        for var in expanded_exp['variations']:\n",
    "            flattened_actions = []\n",
    "            for action in var['actions']:\n",
    "                flattened_changes = []\n",
    "                for element in action['changes']:\n",
    "                    flattened_changes.append(element)\n",
    "\n",
    "                # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "                updated_changes = populating_vals(outer_dict=action, inner_flattened_list=flattened_changes, destination_key='changes')\n",
    "                new_flattened_changes = flatten_dupe_vals(vals=updated_changes, key='changes')\n",
    "\n",
    "            update_actions = populating_vals(outer_dict=var, inner_flattened_list=new_flattened_changes, destination_key='actions')\n",
    "            flattened_actions.extend(flatten_dupe_vals(vals=update_actions, key='actions'))  \n",
    "\n",
    "        update_variations = populating_vals(outer_dict=expanded_exp, inner_flattened_list=flattened_actions, destination_key='variations')\n",
    "        flattened_variations.extend(flatten_dupe_vals(vals=update_variations, key='variations'))\n",
    "\n",
    "        expanded_variations = flattened_variations\n",
    "\n",
    "        expanded_exp = expanded_variations\n",
    "        expanded_exp_list.extend(expanded_exp)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in expanded_exp_list:\n",
    "    print(e.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
