{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import popelines\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbq_key = os.environ.get('GOOGLE_ACCOUNT_CREDENTIALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pope = popelines.popeline(dataset_id='vicky', service_key_file_loc=gbq_key, directory='.', verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Authorization': 'Bearer 2:EWAWmaXb4TgtYVU2VvwoEF-9UbJxBahkiFh1633_Oc9nmju7iJis',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper flatten(jayson, {}, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(jayson, acc, prefix):\n",
    "    if isinstance(jayson, dict):\n",
    "        for k,v in jayson.items():\n",
    "            if prefix:\n",
    "                prefix_k = prefix + \"_\" + k\n",
    "            else: \n",
    "                prefix_k = k\n",
    "            prefix_k = prefix_k.replace('-', '_')\n",
    "            \n",
    "            if isinstance(v, dict):\n",
    "                flatten(v, acc, prefix_k)\n",
    "            elif isinstance(v, list):\n",
    "                for j in v:\n",
    "                    flatten(j, acc, prefix_k)\n",
    "            else:\n",
    "                acc[prefix_k] = v\n",
    "        return acc \n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(arg_1, arg_2):\n",
    "    print(arg_1)\n",
    "    print(arg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_json_keys(**kwargs):\n",
    "    callback(**kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_json_keys(arg_1='results', arg_2='experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_values(value, key, reset_key):\n",
    "        if key == reset_key:\n",
    "            new_list = []\n",
    "            for x in value:\n",
    "                value[x]['result_id'] = x\n",
    "                new_list.append(value[x])\n",
    "            return new_list\n",
    "        else:\n",
    "            return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_j_ts = pope.fix_json_values(callback=fix_values, obj=j_ts, reset_key='results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_j_ts_list = [new_j_ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_j_ts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pope.write_to_json(file_name='results_ts.json', jayson=new_j_ts_list, mode='w')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_file_name = '/schema_temp.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate-schema --keep_nulls < '../uploads/result_ts.json' > 'test_schema.json'\n",
    "os.system(f\"generate-schema --keep_nulls < result_ts.json > {schema_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = open(schema_file_name, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pope.write_to_bq(table_name='result_ts', file_name='result_ts.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Results (from experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all projects\n",
    "response_proj = requests.get('https://api.optimizely.com/v2/projects', headers=headers)\n",
    "j = json.loads(response_proj.text)\n",
    "project_id = list()\n",
    "for p in j:\n",
    "    project_id.append(p['id'])  \n",
    "\n",
    "# get all experiments from one project\n",
    "p_id = project_id[0]  \n",
    "params = (\n",
    "    ('project_id', p_id),\n",
    "    ('per_page', 100),\n",
    ") \n",
    "response_exp = requests.get('https://api.optimizely.com/v2/experiments', headers=headers, params=params)\n",
    "# j_exp contains all experiment id's\n",
    "j_exp = json.loads(response_exp.text)\n",
    "\n",
    "# get results from one experiment\n",
    "# experiment_id = j_exp[0]['id']\n",
    "# response_res = requests.get(f'https://api.optimizely.com/v2/experiments/{experiment_id}/results', headers=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get result time series from one experiment\n",
    "experiment_id = 11365136008\n",
    "response_ts = requests.get(f'https://api.optimizely.com/v2/experiments/{experiment_id}/timeseries', headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_ts = json.loads(response_ts.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(j_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_values(value, key):\n",
    "    if key == 'results':\n",
    "        new_list = []\n",
    "        for x in value:\n",
    "            value[x]['result_id'] = x\n",
    "            new_list.append(value[x])\n",
    "        return new_list\n",
    "    else:\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_j_ts = pope.fix_json_values(callback=fix_values, obj=j_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in new_j_ts.items():\n",
    "    print(key, type(val))\n",
    "    if isinstance(val, list):\n",
    "#         print(f'list: {new_j_ts[key]}')\n",
    "        print(f'list of length: {len(val)}, key is {key}')\n",
    "    elif isinstance(val, dict):\n",
    "#         print(f'dict: {new_j_ts[key]}')\n",
    "        print(f'dict containing keys: {val.keys()}')\n",
    "        for sub_key, sub_val in val.items():\n",
    "            print(sub_key,type(sub_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in new_j_ts['metrics'][0].items():\n",
    "    print(k,type(v))\n",
    "# pp.pprint(new_j_ts['metrics'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in new_j_ts['metrics'][0]['results'][0].items():\n",
    "    print(k, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_j_ts['metrics'][0]['results'][0]['timeseries'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to flatten inner level 'timeseries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_timeseries = []\n",
    "for element in new_j_ts['metrics'][0]['results'][0]['timeseries']:\n",
    "    flattened_timeseries.append(flatten(element, {}, ''))\n",
    "print(len(flattened_timeseries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(flattened_timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace old 'timeseries' with new 'flattened_timeseries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populating_vals(outer_dict, inner_flattened_list, destination_key):\n",
    "    updated_dict = {}\n",
    "    for k, v in outer_dict.items():\n",
    "        if k != destination_key:\n",
    "            updated_dict[k] = v\n",
    "        else:\n",
    "            updated_dict[k] = inner_flattened_list\n",
    "    return updated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dupe_vals(vals, key):\n",
    "    \n",
    "    duped_results = []\n",
    "    for element in vals[key]:\n",
    "        ts_dict = populating_vals(outer_dict=vals, inner_flattened_list=element, destination_key=key)\n",
    "        duped_results.append(ts_dict)\n",
    "\n",
    "    flattened_results = []\n",
    "    for element in duped_results:\n",
    "        flattened_results.append(flatten(element, {}, ''))\n",
    "        \n",
    "    return flattened_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_results = populating_vals(outer_dict=new_j_ts['metrics'][0]['results'][0], inner_flattened_list=flattened_timeseries, destination_key='timeseries')\n",
    "flattened_results = flatten_dupe_vals(vals=updated_results, key='timeseries')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_metrics = populating_vals(outer_dict=new_j_ts['metrics'][0], inner_flattened_list=flattened_results, destination_key='results')\n",
    "flattened_metrics = flatten_dupe_vals(vals=update_metrics, key='results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(new_j_ts, open('somejson.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = new_j_ts['metrics'][0]\n",
    "ts = metric['results'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_metrics = []\n",
    "for metric in new_j_ts['metrics']:\n",
    "    for ts in metric['results']:\n",
    "        flattened_timeseries = []\n",
    "        for element in ts['timeseries']:\n",
    "            flattened_timeseries.append(flatten(element, {}, ''))\n",
    "\n",
    "        # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "        updated_results = populating_vals(outer_dict=ts, inner_flattened_list=flattened_timeseries, destination_key='timeseries')\n",
    "        flattened_results = flatten_dupe_vals(vals=updated_results, key='timeseries')\n",
    "\n",
    "    # Replace old 'metrics' with new 'flattened_results'\n",
    "    update_metrics = populating_vals(outer_dict=metric, inner_flattened_list=flattened_results, destination_key='results')\n",
    "    flattened_metrics.extend(flatten_dupe_vals(vals=update_metrics, key='results'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_metrics[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing main.py project-experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import popelines\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# a function to detect deeply nested json file, with a mix of dictionaries and lists\n",
    "def flatten(jayson, acc, prefix):\n",
    "    if isinstance(jayson, dict):\n",
    "        for k,v in jayson.items():\n",
    "            if prefix:\n",
    "                prefix_k = prefix + \"_\" + k\n",
    "            else: \n",
    "                prefix_k = k\n",
    "            prefix_k = prefix_k.replace('-', '_')\n",
    "            \n",
    "            if isinstance(v, dict):\n",
    "                flatten(v, acc, prefix_k)\n",
    "            elif isinstance(v, list):\n",
    "                for j in v:\n",
    "                    flatten(j, acc, prefix_k)\n",
    "            else:\n",
    "                acc[prefix_k] = v\n",
    "        return acc \n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbq_key = os.environ.get('GOOGLE_ACCOUNT_CREDENTIALS')\n",
    "\n",
    "pope = popelines.popeline(dataset_id='optimizely', service_key_file_loc=gbq_key, directory='.', verbose=False)\n",
    "\n",
    "headers = {\n",
    "    'Authorization': 'Bearer 2:EWAWmaXb4TgtYVU2VvwoEF-9UbJxBahkiFh1633_Oc9nmju7iJis',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Project-Experiment table\n",
    "# get all projects\n",
    "try:\n",
    "    response_proj = requests.get('https://api.optimizely.com/v2/projects', headers=headers)\n",
    "    j_proj = json.loads(response_proj.text)\n",
    "    response_proj.raise_for_status()\n",
    "    print('Successfully read project data.')\n",
    "\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store a list of project metadata\n",
    "project_list = list()\n",
    "\n",
    "for project in j_proj:\n",
    "    p_id = project['id']\n",
    "\n",
    "    # get all experiments from one project\n",
    "    params = (\n",
    "        ('project_id', p_id),\n",
    "        ('per_page', 100),\n",
    "    ) \n",
    "\n",
    "    try:\n",
    "        response_exp = requests.get('https://api.optimizely.com/v2/experiments', headers=headers, params=params)\n",
    "        j_exp = json.loads(response_exp.text)\n",
    "        response_exp.raise_for_status()\n",
    "        print('Successfully read experiment data.')\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "\n",
    "    # loop for all experiments in this project\n",
    "    upload_exp_list = []\n",
    "    for exp in j_exp:\n",
    "        exp['project_id'] = p_id\n",
    "        upload_exp_list.append(flatten(exp, {}, ''))\n",
    "\n",
    "    # upload experiment \n",
    "    pope.write_to_json(file_name='experiments.json', jayson=upload_exp_list, mode='w')\n",
    "    pope.write_to_bq(table_name='experiments', file_name='experiments.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "    print(f\"Successfully uploaded experiment {exp['id']}\")\n",
    "\n",
    "    project_list.append(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing main.py experiment-result-timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import popelines\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def fix_values(value, key, reset_key):\n",
    "    if key == reset_key:\n",
    "        new_list = []\n",
    "        for x in value:\n",
    "            value[x][f'{reset_key}_id'] = x\n",
    "            new_list.append(value[x])\n",
    "        return new_list\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_project_experiment(project_endpoint, experiment_endpoint):\n",
    "\n",
    "    # get all projects\n",
    "    try:\n",
    "        response_proj = requests.get(project_endpoint, headers=headers)\n",
    "        j_proj = json.loads(response_proj.text)\n",
    "        response_proj.raise_for_status()\n",
    "        print('Successfully read project data.')\n",
    "\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "\n",
    "    # store a list of project metadata\n",
    "    project_list = []\n",
    "    experiment_id_list = []\n",
    "\n",
    "    for project in j_proj:\n",
    "        p_id = project['id']\n",
    "\n",
    "        # get all experiments from one project\n",
    "        params = (\n",
    "            ('project_id', p_id),\n",
    "            ('per_page', 100),\n",
    "        ) \n",
    "\n",
    "        try:\n",
    "            response_exp = requests.get(experiment_endpoint, headers=headers, params=params)\n",
    "            j_exp = json.loads(response_exp.text)\n",
    "            response_exp.raise_for_status()\n",
    "            print('Successfully read experiment data.')\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(err)\n",
    "\n",
    "        # loop for all experiments in this project\n",
    "        upload_exp_list = []\n",
    "        for exp in j_exp:\n",
    "            exp['project_id'] = p_id\n",
    "            upload_exp_list.append(flatten(exp, {}, ''))\n",
    "            experiment_id_list.append(exp['id'])\n",
    "            \n",
    "        # upload experiment \n",
    "        # pope.write_to_json(file_name='../uploads/experiments.json', jayson=upload_exp_list, mode='w')\n",
    "        # pope.write_to_bq(table_name='experiments', file_name='../uploads/experiments.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "        # print(f\"Successfully uploaded experiments for project {p_id}\")\n",
    "\n",
    "    project_list.append(project)\n",
    "\n",
    "    # pope.write_to_json(file_name='../uploads/projects.json', jayson=project_list, mode='w')\n",
    "    # pope.write_to_bq(table_name='projects', file_name='../uploads/projects.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "    # print(\"Successfully uploaded all projects.\")\n",
    "\n",
    "    return experiment_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(jayson, acc, prefix):\n",
    "    if isinstance(jayson, dict):\n",
    "        for k,v in jayson.items():\n",
    "            if prefix:\n",
    "                prefix_k = prefix + \"_\" + k\n",
    "            else: \n",
    "                prefix_k = k\n",
    "            prefix_k = prefix_k.replace('-', '_')\n",
    "            \n",
    "            if isinstance(v, dict):\n",
    "                flatten(v, acc, prefix_k)\n",
    "            elif isinstance(v, list):\n",
    "                for j in v:\n",
    "                    flatten(j, acc, prefix_k)\n",
    "            else:\n",
    "                acc[prefix_k] = v\n",
    "        return acc \n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read project data.\n",
      "Successfully read experiment data.\n",
      "Successfully read experiment data.\n",
      "Successfully read experiment data.\n",
      "Successfully read experiment data.\n",
      "Successfully read experiment data.\n"
     ]
    }
   ],
   "source": [
    "gbq_key = os.environ.get('GOOGLE_ACCOUNT_CREDENTIALS')\n",
    "\n",
    "pope = popelines.popeline(dataset_id='optimizely', service_key_file_loc=gbq_key, directory='.', verbose=False)\n",
    "\n",
    "headers = {\n",
    "    'Authorization': 'Bearer 2:EWAWmaXb4TgtYVU2VvwoEF-9UbJxBahkiFh1633_Oc9nmju7iJis',\n",
    "}\n",
    "\n",
    "############################################### Project-Experiment #############################################\n",
    "p_endpoint = 'https://api.optimizely.com/v2/projects'\n",
    "e_endpoint = 'https://api.optimizely.com/v2/experiments'\n",
    "\n",
    "experiment_id = generate_project_experiment(project_endpoint=p_endpoint, experiment_endpoint=e_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ts = []\n",
    "\n",
    "for exp_id in experiment_id:\n",
    "    print(exp_id)\n",
    "    ts_endpoint = f'https://api.optimizely.com/v2/experiments/{exp_id}/timeseries'\n",
    "    # generate_experiment_results(ts_endpoint, experiment_id=exp_id)\n",
    "\n",
    "    response_ts = requests.get(ts_endpoint, headers=headers)\n",
    "    if response_ts.text == '':\n",
    "        # if '' then the experiment has not started yet\n",
    "        j_ts = {'experiment_id': exp_id}\n",
    "    else:\n",
    "        j_ts = json.loads(response_ts.text)\n",
    "\n",
    "    new_j_ts = pope.fix_json_values(callback=fix_values, obj=j_ts, reset_key='results')\n",
    "    # new_j_ts_list = [new_j_ts]\n",
    "\n",
    "    all_ts.append(new_j_ts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
