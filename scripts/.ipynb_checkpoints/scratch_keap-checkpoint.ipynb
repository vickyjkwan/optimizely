{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import popelines\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def fix_values(value, key, reset_key):\n",
    "    if key == reset_key:\n",
    "        new_list = []\n",
    "        for x in value:\n",
    "            value[x][f'{reset_key}_id'] = x\n",
    "            new_list.append(value[x])\n",
    "        return new_list\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(jayson, acc, prefix):\n",
    "    if isinstance(jayson, dict):\n",
    "        for k,v in jayson.items():\n",
    "            if prefix:\n",
    "                prefix_k = prefix + \"_\" + k\n",
    "            else: \n",
    "                prefix_k = k\n",
    "            prefix_k = prefix_k.replace('-', '_')\n",
    "            \n",
    "            if isinstance(v, dict):\n",
    "                flatten(v, acc, prefix_k)\n",
    "            elif isinstance(v, list):\n",
    "                for j in v:\n",
    "                    flatten(j, acc, prefix_k)\n",
    "            else:\n",
    "                acc[prefix_k] = v\n",
    "        return acc \n",
    "    else:\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_project_experiment(project_endpoint, experiment_endpoint):\n",
    "\n",
    "    # get all projects\n",
    "    try:\n",
    "        response_proj = requests.get(project_endpoint, headers=headers)\n",
    "        j_proj = json.loads(response_proj.text)\n",
    "        response_proj.raise_for_status()\n",
    "        print('Successfully read project data.')\n",
    "\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "\n",
    "    # store a list of project metadata\n",
    "    project_list = []\n",
    "    experiment_id_list = []\n",
    "\n",
    "    for project in j_proj:\n",
    "        p_id = project['id']\n",
    "\n",
    "        # get all experiments from one project\n",
    "        params = (\n",
    "            ('project_id', p_id),\n",
    "            ('per_page', 100),\n",
    "        ) \n",
    "\n",
    "        try:\n",
    "            response_exp = requests.get(experiment_endpoint, headers=headers, params=params)\n",
    "            j_exp = json.loads(response_exp.text)\n",
    "            response_exp.raise_for_status()\n",
    "            print('Successfully read experiment data.')\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(err)\n",
    "\n",
    "        # loop for all experiments in this project\n",
    "        upload_exp_list = []\n",
    "        for exp in j_exp:\n",
    "            exp['project_id'] = p_id\n",
    "            upload_exp_list.append(flatten(exp, {}, ''))\n",
    "            experiment_id_list.append(exp['id'])\n",
    "            \n",
    "        # upload experiment \n",
    "        # pope.write_to_json(file_name='../uploads/experiments.json', jayson=upload_exp_list, mode='w')\n",
    "        # pope.write_to_bq(table_name='experiments', file_name='../uploads/experiments.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "        # print(f\"Successfully uploaded experiments for project {p_id}\")\n",
    "\n",
    "    project_list.append(project)\n",
    "\n",
    "    # pope.write_to_json(file_name='../uploads/projects.json', jayson=project_list, mode='w')\n",
    "    # pope.write_to_bq(table_name='projects', file_name='../uploads/projects.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "    # print(\"Successfully uploaded all projects.\")\n",
    "\n",
    "    return experiment_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbq_key = os.environ.get('GOOGLE_ACCOUNT_CREDENTIALS')\n",
    "\n",
    "pope = popelines.popeline(dataset_id='optimizely', service_key_file_loc=gbq_key, directory='.', verbose=False)\n",
    "\n",
    "headers = {\n",
    "    'Authorization': 'Bearer 2:EWAWmaXb4TgtYVU2VvwoEF-9UbJxBahkiFh1633_Oc9nmju7iJis',\n",
    "}\n",
    "\n",
    "############################################### Project-Experiment #############################################\n",
    "p_endpoint = 'https://api.optimizely.com/v2/projects'\n",
    "e_endpoint = 'https://api.optimizely.com/v2/experiments'\n",
    "\n",
    "experiment_id = generate_project_experiment(project_endpoint=p_endpoint, experiment_endpoint=e_endpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ts = []\n",
    "############################################### Experiment-Results #############################################\n",
    "for exp_id in experiment_id:\n",
    "    print(exp_id)\n",
    "    ts_endpoint = f'https://api.optimizely.com/v2/experiments/{exp_id}/timeseries'\n",
    "    # generate_experiment_results(ts_endpoint, experiment_id=exp_id)\n",
    "\n",
    "    response_ts = requests.get(ts_endpoint, headers=headers)\n",
    "    if response_ts.text == '':\n",
    "        # if '' then the experiment has not started yet\n",
    "        j_ts = {'experiment_id': exp_id}\n",
    "    else:\n",
    "        j_ts = json.loads(response_ts.text)\n",
    "\n",
    "    new_j_ts = pope.fix_json_values(callback=fix_values, obj=j_ts, reset_key='results')\n",
    "    # new_j_ts_list = [new_j_ts]\n",
    "\n",
    "    all_ts.append(new_j_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(all_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say \"completed\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_experiment_results(ts_endpoint):\n",
    "    # get result time series from all experiments:\n",
    "    try:\n",
    "        response_ts = requests.get(ts_endpoint, headers=headers)\n",
    "        j_ts = json.loads(response_ts.text)\n",
    "        response_ts.raise_for_status()\n",
    "        print('Successfully read experiment results data.')\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "        \n",
    "    new_j_ts = pope.fix_json_values(callback=fix_values, obj=j_ts, reset_key='results')    \n",
    "    \n",
    "    # with keys properly reset, we need to populate upper level into each row of each list level\n",
    "    # Trying to flatten inner level 'timeseries'\n",
    "    flattened_metrics = []\n",
    "    for metric in new_j_ts['metrics']:\n",
    "        for ts in metric['results']:\n",
    "            flattened_timeseries = []\n",
    "            for element in ts['timeseries']:\n",
    "                flattened_timeseries.append(flatten(element, {}, ''))\n",
    "\n",
    "            # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "            updated_results = populating_vals(outer_dict=ts, inner_flattened_list=flattened_timeseries, destination_key='timeseries')\n",
    "            flattened_results = flatten_dupe_vals(vals=updated_results, key='timeseries')\n",
    "\n",
    "        # Replace old 'metrics' with new 'flattened_results'\n",
    "        update_metrics = populating_vals(outer_dict=metric, inner_flattened_list=flattened_results, destination_key='results')\n",
    "        flattened_metrics.extend(flatten_dupe_vals(vals=update_metrics, key='results'))\n",
    "        \n",
    "    return flattened_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populating_vals(outer_dict, inner_flattened_list, destination_key):\n",
    "    # outer_dict is the upper level dict\n",
    "    # inner_flattened_list is the lower level list of dicts that are each flattened\n",
    "    # destination_key is the primary key of the lower level\n",
    "    updated_dict = {}\n",
    "    for k, v in outer_dict.items():\n",
    "        if k != destination_key:\n",
    "            updated_dict[k] = v\n",
    "        else:\n",
    "            updated_dict[k] = inner_flattened_list\n",
    "    return updated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dupe_vals(vals, key):\n",
    "    \n",
    "    duped_results = []\n",
    "    for element in vals[key]:\n",
    "        ts_dict = populating_vals(outer_dict=vals, inner_flattened_list=element, destination_key=key)\n",
    "        duped_results.append(ts_dict)\n",
    "\n",
    "    flattened_results = []\n",
    "    for element in duped_results:\n",
    "        flattened_results.append(flatten(element, {}, ''))\n",
    "        \n",
    "    return flattened_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_endpoint='https://api.optimizely.com/v2/experiments/11402551541/timeseries'\n",
    "try:\n",
    "    response_ts = requests.get(ts_endpoint, headers=headers)\n",
    "    j_ts = json.loads(response_ts.text)\n",
    "    response_ts.raise_for_status()\n",
    "    print('Successfully read experiment results data.')\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(err)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_j_ts = pope.fix_json_values(callback=fix_values, obj=j_ts, reset_key='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with keys properly reset, we need to populate upper level into each row of each list level\n",
    "# Trying to flatten inner level 'timeseries'\n",
    "flattened_metrics = []\n",
    "for metric in new_j_ts['metrics']:\n",
    "    for ts in metric['results']:\n",
    "        flattened_timeseries = []\n",
    "        for element in ts['timeseries']:\n",
    "            flattened_timeseries.append(flatten(element, {}, ''))\n",
    "\n",
    "        # Replace old 'timeseries' with new 'flattened_timeseries'\n",
    "        updated_results = populating_vals(outer_dict=ts, inner_flattened_list=flattened_timeseries, destination_key='timeseries')\n",
    "        flattened_results = flatten_dupe_vals(vals=updated_results, key='timeseries')\n",
    "\n",
    "    # Replace old 'metrics' with new 'flattened_results'\n",
    "    update_metrics = populating_vals(outer_dict=metric, inner_flattened_list=flattened_results, destination_key='results')\n",
    "    flattened_metrics.extend(flatten_dupe_vals(vals=update_metrics, key='results'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = generate_experiment_results(ts_endpoint='https://api.optimizely.com/v2/experiments/11402551541/timeseries')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in ts:\n",
    "    print(e['results_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pope.write_to_json(file_name='results_ts.json', jayson=ts, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pope.write_to_bq(table_name='result_ts', file_name='results_ts.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all projects\n",
    "# try:\n",
    "#     response_proj = requests.get('https://api.optimizely.com/v2/projects', headers=headers)\n",
    "#     j_proj = json.loads(response_proj.text)\n",
    "#     response_proj.raise_for_status()\n",
    "#     print('Successfully read project data.')\n",
    "\n",
    "# except requests.exceptions.HTTPError as err:\n",
    "#     print(err)\n",
    "\n",
    "# # store a list of project metadata\n",
    "# project_list = []\n",
    "experiment_id_list = []\n",
    "\n",
    "# for project in j_proj:\n",
    "    p_id = project['id']\n",
    "\n",
    "    # get all experiments from one project\n",
    "    params = (\n",
    "        ('project_id', p_id),\n",
    "        ('per_page', 100),\n",
    "    ) \n",
    "\n",
    "    try:\n",
    "        response_exp = requests.get('https://api.optimizely.com/v2/experiments', headers=headers, params=params)\n",
    "        j_exp = json.loads(response_exp.text)\n",
    "        response_exp.raise_for_status()\n",
    "        print('Successfully read experiment data.')\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(err)\n",
    "\n",
    "    # loop for all experiments in this project\n",
    "    upload_exp_list = []\n",
    "    for exp in j_exp:\n",
    "        exp['project_id'] = p_id\n",
    "        upload_exp_list.append(flatten(exp, {}, ''))\n",
    "        experiment_id_list.append(exp['id'])\n",
    "\n",
    "    # upload experiment \n",
    "    # pope.write_to_json(file_name='../uploads/experiments.json', jayson=upload_exp_list, mode='w')\n",
    "    # pope.write_to_bq(table_name='experiments', file_name='../uploads/experiments.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "    # print(f\"Successfully uploaded experiments for project {p_id}\")\n",
    "\n",
    "# project_list.append(project)\n",
    "\n",
    "# pope.write_to_json(file_name='../uploads/projects.json', jayson=project_list, mode='w')\n",
    "# pope.write_to_bq(table_name='projects', file_name='../uploads/projects.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "# print(\"Successfully uploaded all projects.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_id = 10849384554\n",
    "\n",
    "# get all experiments from one project\n",
    "params = (\n",
    "    ('project_id', p_id),\n",
    "    ('per_page', 100),\n",
    ") \n",
    "\n",
    "try:\n",
    "    response_exp = requests.get('https://api.optimizely.com/v2/experiments', headers=headers, params=params)\n",
    "    j_exp = json.loads(response_exp.text)\n",
    "    response_exp.raise_for_status()\n",
    "    print('Successfully read experiment data.')\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print(err)\n",
    "\n",
    "# loop for all experiments in this project\n",
    "upload_exp_list = []\n",
    "for exp in j_exp:\n",
    "    exp['project_id'] = p_id\n",
    "    upload_exp_list.append(exp)\n",
    "#     upload_exp_list.append(flatten(exp, {}, ''))\n",
    "#     experiment_id_list.append(exp['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_exp_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in upload_exp_list:\n",
    "    print(e['variations_variation_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pope.write_to_json(file_name='experiments.json', jayson=upload_exp_list, mode='w')\n",
    "pope.write_to_bq(table_name='test_experiments', file_name='experiments.json', append=True, ignore_unknown_values=False, bq_schema_autodetect=False)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
